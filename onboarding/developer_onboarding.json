{
  "getting_started": {
    "description": "Video translation pipeline with Service architecture - get up and running quickly",
    "project_info": {
      "main_entry_point": "src/videodub/core/pipeline.py",
      "cli_command": "python examples/quick_test.py",
      "package_manager": "poetry",
      "python_version": "3.8+"
    },
    "dependencies": {
      "external_tools": ["ffmpeg", "yt-dlp"],
      "api_keys_required": ["OPENAI_API_KEY"],
      "api_keys_optional": ["GOOGLE_APPLICATION_CREDENTIALS", "AZURE_SPEECH_KEY"]
    },
    "development": {
      "install_command": "poetry install",
      "test_command": "make test",
      "lint_command": "make lint",
      "format_command": "make format",
      "quick_test": "python examples/quick_test.py"
    },
    "key_files": {
      "main_pipeline": "src/videodub/core/pipeline.py",
      "service_interfaces": "src/videodub/core/interfaces.py",
      "data_models": "src/videodub/core/models.py",
      "configuration": "src/videodub/config/settings.py",
      "examples": "examples/"
    },
    "documentation": {
      "architecture_overview": {
        "location": "docs/architecture/",
        "current_architecture": "docs/architecture/current_architecture.md",
        "description": "Complete technical overview of the current system"
      },
      "architecture_decisions": {
        "location": "docs/adr/",
        "index": "docs/adr/README.md",
        "description": "Architecture Decision Records documenting key design decisions",
        "key_current_adrs": [
          {
            "adr": "0001",
            "title": "Pipeline Architecture Design",
            "status": "Accepted",
            "relevance": "Core system architecture"
          },
          {
            "adr": "0002", 
            "title": "Real-Time Cost Tracking Integration",
            "status": "Accepted",
            "relevance": "Cost monitoring and analytics"
          },
          {
            "adr": "0005",
            "title": "Pipeline Step Separation and Responsibility Alignment",
            "status": "Accepted",
            "relevance": "Fundamental pipeline architecture - see implementation archive",
            "implementation_archive": "docs/architecture/adr_0005_implementation/"
          },
          {
            "adr": "0006",
            "title": "Speech Timing Model Redesign",
            "status": "Proposed",
            "relevance": "Natural speech timing vs subtitle display timing - fixes overlapping segments"
          }
        ]
      },
      "testing_strategy": {
        "location": "docs/testing_strategy.md",
        "description": "Environment-adaptive testing strategy with CI/Local configurations",
        "status": "Complete",
        "commands": {
          "fast_tests": "make test-fast",
          "performance_fast": "make test-performance-fast",
          "all_tests": "make test"
        }
      }
    },
    "current_architecture": {
      "status": "Service-Based Architecture - ADR-0005 Accepted",
      "description": "Service-based architecture with separated responsibilities",
      "implementation_history": {
        "archive_location": "docs/architecture/adr_0005_implementation/",
        "description": "Complete 6-phase implementation history archived for reference",
        "status": "All phases complete - system fully migrated to service-based architecture"
      },
      "architecture_evolution": {
        "legacy_pipeline": "video → transcription → translation → tts → audio → video",
        "current_pipeline": "video → data_extraction → translation → alignment → tts → audio → video",
        "key_improvement": "Separation between data extraction, translation, and timing alignment"
      }
    },
    "pipeline_services": [
      {
        "name": "Data Extraction",
        "component": "DataExtractionService",
        "file_path": "src/videodub/services/data_extraction.py",
        "implementation": "YouTubeDataExtractionService",
        "input": ["Video URL"],
        "output": ["DataExtractionResult (TimedTranscript + file paths)"],
        "description": "Extracts transcript, timing metadata, and file paths from video sources (YouTube API, future: speech-to-text)",
        "status": "Production Ready",
        "responsibility": "Extract all available data and provide explicit file paths for robust pipeline processing",
        "key_capabilities": ["YouTube API integration", "File path tracking", "Quality scoring", "Future: speech-to-text"]
      },
      {
        "name": "Translation",
        "component": "TranslationService", 
        "file_path": "src/videodub/services/translator.py",
        "implementation": "OpenAITranslationService",
        "input": ["List[str] (extracted from TimedTranscript.segments)"],
        "output": ["List[str] (translated texts)"],
        "description": "Pure text-to-text translation using OpenAI GPT models",
        "status": "Production Ready",
        "responsibility": "Pure text translation with no timing or alignment concerns",
        "key_capabilities": ["Pure text translation", "Batch processing", "Optimized variant available"]
      },
      {
        "name": "Alignment",
        "component": "AlignmentService",
        "file_path": "src/videodub/services/alignment.py", 
        "implementation": "TimingAlignmentService",
        "input": ["TimedTranscript", "List[str] (translated texts)", "target_language", "AlignmentConfig"],
        "output": ["TimedTranslation"],
        "description": "Synchronizes translated text with original speech timing metadata using configurable alignment strategies",
        "status": "Production Ready",
        "responsibility": "Synchronize translated text with original timing, handle segment length mismatches, apply speech timing optimization",
        "key_capabilities": ["Multiple alignment strategies", "A/B testing", "Quality scoring", "Built-in evaluation"]
      },
      {
        "name": "Text-to-Speech",
        "component": "TTSService",
        "file_path": "src/videodub/services/tts.py",
        "implementation": "OpenAITTSService", 
        "input": ["TimedTranslation", "target_language"],
        "output": ["AudioFiles"],
        "description": "Generates natural-sounding audio from aligned translated segments using OpenAI TTS or other engines",
        "status": "Production Ready",
        "responsibility": "Convert aligned translated text to speech audio files",
        "key_capabilities": ["Multiple TTS engines", "Batch generation", "Concurrent optimization available"]
      },
      {
        "name": "Audio Processing",
        "component": "AudioProcessingService",
        "file_path": "src/videodub/services/audio.py",
        "implementation": "FFmpegAudioProcessingService",
        "input": ["AudioFiles", "TimedTranslation"],
        "output": ["CombinedAudioFile"], 
        "description": "Combines individual audio segments into a single synchronized audio track",
        "status": "Stable",
        "responsibility": "Synchronize and combine translated audio segments",
        "key_capabilities": ["Audio synchronization", "FFmpeg-based processing"]
      },
      {
        "name": "Video Dubbing",
        "component": "VideoProcessingService",
        "file_path": "src/videodub/services/video.py",
        "implementation": "FFmpegVideoProcessingService",
        "input": ["OriginalVideo", "CombinedAudioFile"],
        "output": ["DubbedVideo"],
        "description": "Creates final dubbed video by replacing original audio with translated audio using FFmpeg",
        "status": "Production Ready",
        "responsibility": "Combine original video with translated audio track",
        "key_capabilities": ["Video-audio synchronization", "Multiple format support"]
      },
      {
        "name": "Storage & Result",
        "component": "StorageService",
        "file_path": "src/videodub/services/storage.py",
        "implementation": "StorageService", 
        "input": ["VideoMetadata", "TimedTranscript", "TimedTranslation", "AudioFiles", "DubbedVideo"],
        "output": ["ProcessingResult"],
        "description": "Saves all pipeline outputs and generates processing result with file paths",
        "status": "Production Ready",
        "responsibility": "Persist all pipeline data and generate comprehensive processing results",
        "key_capabilities": ["Data persistence", "Result generation", "A/B testing storage"]
      }
    ],
    "performance_optimizations": {
      "description": "Optimized variants available for production workloads",
      "translation": "OptimizedOpenAITranslationService (90% faster, src/videodub/services/optimized_translator.py)",
      "tts": "ConcurrentTTSOptimizer (2.4x speedup, src/videodub/services/optimized_translator.py)"
    },
    "cost_tracking": {
      "file_path": "src/videodub/utils/cost_tracking.py",
      "description": "Real-time API cost monitoring for translation and TTS calls"
    },
    "planned_enhancements": {
      "speech_timing_redesign": {
        "adr": "ADR-0006", 
        "description": "Replace YouTube subtitle timing with natural speech duration estimation",
        "problem": "Current overlapping segments (4+ simultaneous) make alignment difficult",
        "affects": ["DataExtractionService", "AlignmentService", "AudioProcessingService"]
      }
    },
    "current_implementation": {
      "adr_0006_implementation": {
        "status": "In Progress",
        "description": "Speech Timing Model Redesign - Fix YouTube Data Misinterpretation with Proper Separation of Concerns",
        "current_phase": "Phase 1: Model Enhancement",
        "critical_insight": "YouTube duration = subtitle display time (NOT speech time). Preserve all data with correct labels, move speech estimation to AlignmentService to maintain separation of concerns.",
        "pipeline_design": {
          "data_extraction": "Preserve YouTube data with correct labels: start_time, subtitle_display_duration, text, end_time=None",
          "translation": "Pure text translation, no timing changes",
          "alignment": "Complete timing here: end_time = start_time + estimated_speech_duration(text)",
          "audio_processing": "Works with corrected speech timing"
        },
        "phases": [
          {
            "phase": 1,
            "name": "Model Enhancement",
            "duration": "2-3 days",
            "status": "pending",
            "components": ["Enhanced TranscriptSegment Model", "Speech Duration Estimator"],
            "files": ["src/videodub/core/models.py", "src/videodub/core/speech_estimation.py"],
            "goal": "Preserve all YouTube data with correct labels, create speech estimation foundation",
            "key_changes": [
              "TranscriptSegment: add subtitle_display_duration field (preserve YouTube duration)",
              "TranscriptSegment: end_time becomes optional (incomplete timing from extraction)", 
              "Create SpeechDurationEstimator for AlignmentService to use"
            ]
          },
          {
            "phase": 2,
            "name": "Data Extraction Update", 
            "duration": "1-2 days",
            "status": "pending",
            "components": ["YouTubeDataExtractionService Updates", "Timing Metadata Clarification"],
            "files": ["src/videodub/services/data_extraction.py"],
            "goal": "Output incomplete timing with preserved YouTube data, correctly labeled",
            "key_changes": [
              "Set end_time=None (incomplete timing)",
              "Store YouTube duration as subtitle_display_duration",
              "Update timing metadata to reflect incomplete timing"
            ]
          },
          {
            "phase": 3,
            "name": "Alignment Service Enhancement",
            "duration": "2-3 days", 
            "status": "pending",
            "components": ["Speech Duration Integration", "Timing Completion Logic"],
            "files": ["src/videodub/services/alignment.py"],
            "goal": "Complete timing in AlignmentService using speech estimation",
            "key_changes": [
              "Integrate SpeechDurationEstimator into AlignmentService",
              "Complete end_time calculation: start_time + estimated_speech_duration",
              "Handle natural pauses between speech segments"
            ]
          },
          {
            "phase": 4,
            "name": "Audio Pipeline Validation",
            "duration": "1-2 days",
            "status": "pending", 
            "components": ["TTS Service Validation", "Audio Processing Validation"],
            "files": ["src/videodub/services/audio.py", "src/videodub/services/tts.py"],
            "goal": "Validate audio pipeline works with corrected speech timing",
            "key_changes": [
              "Verify TTS works with speech-only durations",
              "Handle natural pauses in audio processing",
              "Test end-to-end audio generation"
            ]
          },
          {
            "phase": 5,
            "name": "Testing & Validation",
            "duration": "1-2 days",
            "status": "pending",
            "components": ["Speech Timing Tests", "Pipeline Integration Tests"],
            "files": ["tests/"],
            "goal": "Comprehensive testing of corrected timing model",
            "key_changes": [
              "Test speech duration estimation accuracy",
              "Validate zero overlapping segments",
              "End-to-end pipeline tests"
            ]
          },
          {
            "phase": 6,
            "name": "Documentation & Future Planning", 
            "duration": "1 day",
            "status": "pending",
            "components": ["Documentation Updates", "Model Refactoring Planning"],
            "files": ["docs/architecture/", "docs/adr/0006-speech-timing-model-redesign.md"],
            "goal": "Document changes and plan future model name refactoring",
            "key_changes": [
              "Update architecture documentation",
              "Plan future refactoring of misleading model names (TimedTranscript, etc.)"
            ]
          }
        ],
        "total_estimated_duration": "8-12 days",
        "success_criteria": "Zero overlapping segments, natural speech timing, preserved YouTube data with correct labels, maintained separation of concerns",
        "future_work": "Refactor misleading model names (TimedTranscript, TimedTranslation) to better reflect actual data flow"
      }
    }
  }
}